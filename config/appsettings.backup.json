{
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft": "Warning",
      "Microsoft.Hosting.Lifetime": "Information"
    }
  },
  "DefaultMode": "Intelligent",
  "DefaultClient": "ollama",
  "PythonSubsystem": {
    "Enabled": true,
    "Path": "python_subsystem",
    "Script": "main.py",
    "Port": 8000,
    "StartupTimeoutSeconds": 10,
    "ShutdownTimeoutSeconds": 5
  },
  "OllamaSettings": {
    "BaseUrl": "http://localhost:11434",
    "ApiEndpoint": "http://localhost:11434/api",
    "GenerateEndpoint": "http://localhost:11434/api/generate",
    "ChatEndpoint": "http://localhost:11434/api/chat",
    "ModelsEndpoint": "http://localhost:11434/api/tags",
    "DefaultModel": "llama3.1:8b-instruct-q4_K_M",
    "CoderModel": "llama3.1:8b-instruct-q4_K_M",
    "ThinkerModel": "llama3.1:8b-instruct-q4_K_M",
    "ConnectionTimeout": 30,
    "RequestTimeout": 120,
    "MaxRetries": 3,
    "RetryDelay": 1000
  },
  "LMStudioSettings": {
    "BaseUrl": "http://localhost:1234",
    "ApiEndpoint": "http://localhost:1234/v1",
    "ChatEndpoint": "http://localhost:1234/v1/chat/completions",
    "ModelsEndpoint": "http://localhost:1234/v1/models",
    "DefaultModel": "llama-3.1-8b-instruct",
    "CoderModel": "llama-3.1-8b-instruct",
    "ThinkerModel": "llama-3.1-8b-instruct",
    "ConnectionTimeout": 30,
    "RequestTimeout": 120,
    "MaxRetries": 3,
    "RetryDelay": 1000,
    "ApiKey": null,
    "Temperature": 0.1,
    "TopP": 0.9,
    "MaxTokens": 2048
  },
  "AgentSettings": {
    "MaxConcurrentAgents": 5,
    "DefaultAgentTimeout": 60,
    "CollaborationEnabled": true,
    "ExecutionTreeDepth": 10,
    "ClearCacheOnStartup": false
  },
  "ModeSettings": {
    "SingleQuery": {
      "Enabled": true,
      "DefaultModel": "llama3.1:8b-instruct-q4_K_M"
    },
    "Intelligent": {
      "Enabled": true,
      "DefaultModel": "llama3.1:8b-instruct-q4_K_M",
      "UseContextSwitching": true
    },
    "Collaborative": {
      "Enabled": true,
      "MaxCollaborators": 3,
      "SyncInterval": 5000
    }
  },
  "LLM": {
    "EndpointUrl": "http://localhost:11434/api/chat"
  },
  "Infrastructure": {
    "CacheEnabled": true,
    "CacheExpirationMinutes": 30,
    "LogRequests": true,
    "LogResponses": false
  },
  "Cursor": {
    "UseFullPaths": false,
    "IncludeDebugPaths": true,
    "PathSeparator": "/"
  }
}
